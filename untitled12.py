# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I8--H9dLbbI7uFagm4wpYLwYJtl9j8PQ
"""

# identical_final_dataset_cleaning.py
import pandas as pd
import numpy as np
from pathlib import Path

# Replace Colab-specific paths with local paths
INPUT_FILE = "c:\\Users\\Giri prasad\\Desktop\\j\\Combined_2016_2024_Data.xlsx"
OUTPUT_FILE = "c:\\Users\\Giri prasad\\Desktop\\j\\Final_dataset.xlsx"
ACTIONABLE_OUTPUT_FILE = "c:\\Users\\Giri prasad\\Desktop\\j\\Final_dataset_actionable_solutions.xlsx"
OUTPUT_DIR = Path("c:\\Users\\Giri prasad\\Desktop\\j\\notebook_output")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

MISSING_THRESHOLD = 0.5
print("ðŸ”¹ Loading dataset...")

df = pd.read_excel(INPUT_FILE)
print("Original shape:", df.shape)

df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
df = df.dropna(axis=1, how='all')

for col in df.select_dtypes(include=['object']).columns:
    df[col] = (
        df[col]
        .astype(str)
        .str.strip()
        .replace({'nan': np.nan, 'none': np.nan, 'unknown': np.nan, 'n/a': np.nan, '': np.nan})
    )
    df[col] = df[col].str.lower()

for date_col in ["start_date", "end_date"]:
    if date_col in df.columns:
        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')

if "duration" in df.columns:
    df["duration"] = pd.to_numeric(df["duration"], errors="coerce")

mask = df["end_date"].isna() & df["start_date"].notna() & df["duration"].notna()
df.loc[mask, "end_date"] = df.loc[mask, "start_date"] + pd.to_timedelta(df.loc[mask, "duration"], unit="D")

mask_dur = df["duration"].isna() & df["start_date"].notna() & df["end_date"].notna()
df.loc[mask_dur, "duration"] = (df.loc[mask_dur, "end_date"] - df.loc[mask_dur, "start_date"]).dt.days

mask_same_day = df["start_date"].notna() & (df["start_date"] == df["end_date"])
df.loc[mask_same_day, "duration"] = 1


if {"country", "shutdown_type", "duration"}.issubset(df.columns):
    medians = (
        df.groupby(["country", "shutdown_type"])["duration"]
        .median()
        .reset_index()
        .rename(columns={"duration": "median_duration"})
    )
    df = df.merge(medians, on=["country", "shutdown_type"], how="left")

    mask_fill = df["end_date"].isna() & df["start_date"].notna() & df["median_duration"].notna()
    df.loc[mask_fill, "end_date"] = df.loc[mask_fill, "start_date"] + pd.to_timedelta(df.loc[mask_fill, "median_duration"], unit="D")

    mask_dur_fill = df["duration"].isna() & df["median_duration"].notna()
    df.loc[mask_dur_fill, "duration"] = df.loc[mask_dur_fill, "median_duration"]

    df = df.drop(columns=["median_duration"], errors="ignore")

invalid = df["end_date"].isna() | ((df["end_date"] < df["start_date"]) & df["start_date"].notna())
print(f"Dropping {invalid.sum()} invalid rows.")
df = df[~invalid].copy()

if "duration" in df.columns:
    negative_duration_mask = df["duration"] < 0
    print(f"Dropping {negative_duration_mask.sum()} rows with negative duration.")
    df = df[~negative_duration_mask].copy()


missing_ratio = df.isna().mean()
cols_to_drop = missing_ratio[missing_ratio > MISSING_THRESHOLD].index.tolist()
df = df.drop(columns=cols_to_drop)
print(f"Dropped {len(cols_to_drop)} sparse columns.")

binary_cols = [c for c in df.columns if df[c].dropna().isin(['yes', 'no']).all()]
for c in binary_cols:
    df[c] = df[c].fillna("no")

cat_cols = [c for c in df.select_dtypes(include="object").columns if c not in binary_cols]
for c in cat_cols:
    if df[c].isna().any():
        mode_val = df[c].mode()
        if not mode_val.empty:
            df[c] = df[c].fillna(mode_val[0])

mask_final = df["duration"].isna() & df["start_date"].notna() & df["end_date"].notna()
df.loc[mask_final, "duration"] = (df.loc[mask_final, "end_date"] - df.loc[mask_final, "start_date"]).dt.days

mask_same_day_final = df["start_date"].notna() & (df["start_date"] == df["end_date"])
df.loc[mask_same_day_final, "duration"] = 1

#Synthetic Data
def create_synthetic_data(df, num_synthetic_samples=100):
    """Creates synthetic data points by sampling and perturbing existing data."""
    if df.empty:
        return df

    synthetic_df = df.sample(n=num_synthetic_samples, replace=True).copy().reset_index(drop=True)

    for col in synthetic_df.columns:

        if synthetic_df[col].dtype.kind in 'biufc':
            if synthetic_df[col].std() > 0:
                noise = np.random.normal(0, synthetic_df[col].std() * 0.05, num_synthetic_samples) # Add 5% noise
                synthetic_df[col] += noise

                if col == 'duration':
                    synthetic_df[col] = synthetic_df[col].apply(lambda x: max(1, round(x)))
                else:
                     synthetic_df[col] = synthetic_df[col].round().astype(synthetic_df[col].dtype) # Round to original type

        elif synthetic_df[col].dtype == 'object' or isinstance(synthetic_df[col].dtype, pd.CategoricalDtype):
             if synthetic_df[col].nunique() > 1:

                 pass

    return synthetic_df

print(f"\nAdding {400} synthetic data points...")
synthetic_data = create_synthetic_data(df, num_synthetic_samples=400)
df = pd.concat([df, synthetic_data], ignore_index=True)
print("Shape after augmentation:", df.shape)

before = df.shape[0]
df = df.drop_duplicates().reset_index(drop=True)
after = df.shape[0]
print(f"Removed {before - after} duplicate rows.")

df.to_excel(OUTPUT_FILE, index=False)
print(f"\nâœ… Dataset successfully cleaned and saved as {OUTPUT_FILE}")
print("Final shape:", df.shape)

# actionable_solutions.py
import pandas as pd
import numpy as np
import re

INPUT_FILE = "/content/Final_dataset.xlsx"
OUTPUT_FILE = "Final_dataset_actionable_solutions.xlsx"
MAX_LEN = 140

def clean_text(x):
    if pd.isna(x):
        return ""
    s = str(x).lower().strip()
    s = re.sub(r'[^a-z0-9 ,]', ' ', s)
    s = re.sub(r'\s+', ' ', s)
    return s

def pick_area(row):
    a = row.get('area_name', '')
    if pd.isna(a) or str(a).strip() == '':
        return ""
    return str(a).strip()

def pick_network(row):
    net = row.get('affected_network', '')
    if pd.isna(net) or str(net).strip() == '':
        return ""

    first = str(net).split(',')[0].strip()
    return first

ACTION_TEMPLATES = {
    "ddos": "Block attack traffic at the edge and enable DDoS mitigation services.",
    "cyber": "Isolate affected servers, block malicious IPs, and restore from clean backups.",
    "attack": "Block malicious IPs, isolate affected systems, and recover from backups.",
    "fiber": "Repair the broken fiber cable in {area} and reroute traffic via backup path.",
    "subsea": "Coordinate with cable operator to repair subsea cable and route via backups.",
    "cable": "Repair damaged cable in {area} and switch traffic to alternate links.",
    "power": "Restore power sources (generators/UPS) and restart core network nodes.",
    "maintenance": "Complete maintenance steps and run verification tests to bring services online.",
    "technical": "Restart or replace faulty network hardware and validate configurations.",
    "court": "Coordinate with legal teams and restore services when authorized by court.",
    "legal": "Engage legal/comms and restore access once lawful clearance is provided.",
    "protest": "Apply targeted access limits in affected areas and keep emergency lines open.",
    "violence": "Keep emergency communications open and apply localized network controls.",
    "facebook": "Contact Facebook for status and restore access via platform cooperation.",
    "whatsapp": "Coordinate with WhatsApp to allow essential messaging and prevent misuse.",
    "twitter": "Work with Twitter to enable verified accounts and reduce misinformation.",
    "youtube": "Engage CDN/platform to restore video delivery and clear affected caches.",
    "misinformation": "Remove false posts and amplify verified official updates.",
    "hate": "Block hate content and prioritize takedown of abusive accounts.",
    "isp": "Contact ISPs to fix BGP/peering and restore routing between providers.",
    "network": "Restart core routers, verify BGP/DNS, and reroute traffic if needed.",
    "internet": "Check ISP peering, restart core routers, and restore BGP routes.",
    "slow": "Clear congestion by reallocating capacity and prioritizing critical services.",
    "router": "Reboot or replace the faulty router and verify routing tables."
}

#Severity
def derive_severity(row):
    try:
        dur = int(row.get('duration')) if not pd.isna(row.get('duration')) else None
    except:
        dur = None
    extent = clean_text(row.get('shutdown_extent', ''))
    if dur is not None:
        if dur >= 14:
            return 'critical'
        if dur >= 4:
            return 'high'
        if dur >= 2:
            return 'moderate'
        return 'low'
    if 'national' in extent or 'country' in extent:
        return 'high'
    if 'regional' in extent or 'state' in extent:
        return 'moderate'
    return 'low'

#Confidence
def derive_confidence(matched_keywords, row):
    dur_present = not pd.isna(row.get('duration'))
    if matched_keywords and dur_present:
        return 'high'
    if matched_keywords:
        return 'medium'
    return 'low'

def compose_action(row):

    combined = " ".join([
        clean_text(row.get('actual_cause', '')),
        clean_text(row.get('shutdown_type', '')),
        clean_text(row.get('affected_network', '')),
        clean_text(row.get('gov_justification', '')),
        clean_text(row.get('ordered_by', ''))
    ])
    matched = []
    for kw in ACTION_TEMPLATES:
        if kw in combined:
            matched.append(kw)
    area = pick_area(row)
    network = pick_network(row)

    if matched:

        primary = matched[0]
        template = ACTION_TEMPLATES[primary]

        sol = template.format(area=area if area else "the area",
                              network=network if network else "the affected network")
    else:

        sol = "Restart core routers, check ISP peering and DNS, and dispatch engineers if physical lines are damaged."

    sol = sol.strip()
    sol = sol.replace("in the area", "locally")
    sol = sol.replace("the area", "the affected area")
    if len(sol) > MAX_LEN:
        sol = sol[:MAX_LEN-3].rsplit(' ',1)[0] + "..."
    return sol, matched

df = pd.read_excel(INPUT_FILE)

for c in ['start_date','end_date','duration']:
    if c not in df.columns:
        df[c] = np.nan

results = df.apply(lambda r: compose_action(r), axis=1)
df['solutions'] = results.map(lambda x: x[0])
matched_lists = results.map(lambda x: x[1])

df['severity'] = df.apply(derive_severity, axis=1)
df['confidence'] = [derive_confidence(matched, row) for matched, (_, row) in zip(matched_lists, df.iterrows())]

# Save result
df.to_excel(OUTPUT_FILE, index=False)
print("âœ… Actionable solutions saved to:", OUTPUT_FILE)

import os, math, time, joblib, json
from sklearn.model_selection import KFold, StratifiedKFold, cross_val_predict
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.linear_model import ElasticNet, LogisticRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier, GradientBoostingRegressor, GradientBoostingClassifier
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, balanced_accuracy_score, f1_score, confusion_matrix, classification_report
from rapidfuzz import process, fuzz

DATA_PATH = '/content/Final_dataset_actionable_solutions.xlsx'
OUTPUT_DIR = Path('/content/notebook_output')
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
REG_TARGET = 'duration'
CLF_TARGET = 'solutions'

if not os.path.exists(DATA_PATH):
    print('Dataset not found at', DATA_PATH)
    print('If using Colab: from google.colab import files; uploaded = files.upload(); then set DATA_PATH to the uploaded filename')
df = pd.read_excel(DATA_PATH)
print('Loaded dataset shape:', df.shape)
print('Columns:', df.columns.tolist())

#EDA
print("\nMissing values (top 20):")
print(df.isna().sum().sort_values(ascending=False).head(20))
if REG_TARGET not in df.columns or CLF_TARGET not in df.columns:
    raise ValueError(f"Expected targets {REG_TARGET} and {CLF_TARGET} not found. Edit REG_TARGET / CLF_TARGET accordingly.")

# Datetime features
if 'start_date' in df.columns:
    df['start_date'] = pd.to_datetime(df['start_date'], errors='coerce')
    df['start_year'] = df['start_date'].dt.year
    df['start_month'] = df['start_date'].dt.month
    df['start_day'] = df['start_date'].dt.day
    df['start_hour'] = df['start_date'].dt.hour
    df['start_weekday'] = df['start_date'].dt.dayofweek
    df.drop(columns=['start_date'], inplace=True)

# Droping some raw columns (tuneable)
DROP_COLS = [c for c in ['info_source_link'] if c in df.columns]
print('Dropping:', DROP_COLS)
df = df.drop(columns=DROP_COLS)
df = df.dropna(subset=[REG_TARGET, CLF_TARGET]).reset_index(drop=True)
print('After dropping missing targets:', df.shape)

# Feature split
X = df.drop(columns=[REG_TARGET, CLF_TARGET])
y_reg = df[REG_TARGET].astype(float)
y_clf = df[CLF_TARGET].astype(str)

numeric_cols = X.select_dtypes(include=['number']).columns.tolist()
object_cols = X.select_dtypes(include=['object','category']).columns.tolist()

text_cols = []
for c in object_cols:
    avg_len = X[c].fillna('').astype(str).map(len).mean()
    nunique = X[c].nunique(dropna=True)
    if (nunique > 50 and avg_len > 20) or ('detail' in c.lower() or 'note' in c.lower() or 'description' in c.lower()):
        text_cols.append(c)
cat_cols = [c for c in object_cols if c not in text_cols]

print('numeric_cols:', numeric_cols)
print('cat_cols:', cat_cols)
print('text_cols:', text_cols)

#TF-IDF + SVD
if text_cols:
    texts = X[text_cols].fillna('').agg(' '.join, axis=1).values
    tfidf = TfidfVectorizer(max_features=4000, ngram_range=(1,2))
    svd = TruncatedSVD(n_components=50, random_state=42)
    X_text_tfidf = tfidf.fit_transform(texts)
    X_text = svd.fit_transform(X_text_tfidf)
    print('Text features shape:', X_text.shape)
else:
    X_text = None

# Preprocessor for numeric + categorical
numeric_pipe = Pipeline([('impute', SimpleImputer(strategy='median')), ('scale', StandardScaler())])
low_card = [c for c in cat_cols if X[c].nunique() <= 20]
high_card = [c for c in cat_cols if c not in low_card]

cat_low_pipe = Pipeline([('impute', SimpleImputer(strategy='constant', fill_value='missing')), ('ohe', OneHotEncoder(handle_unknown='ignore'))])
cat_high_pipe = Pipeline([('impute', SimpleImputer(strategy='constant', fill_value='missing')), ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])

transformers = []
if numeric_cols:
    transformers.append(('num', numeric_pipe, numeric_cols))
if low_card:
    transformers.append(('cat_low', cat_low_pipe, low_card))
if high_card:
    transformers.append(('cat_high', cat_high_pipe, high_card))

preprocessor = ColumnTransformer(transformers, remainder='drop')
X_numcat = preprocessor.fit_transform(X)
print('Numeric+Cat transformed shape:', X_numcat.shape)

import numpy as np

if X_text is not None:
    X_numcat_dense = X_numcat.toarray() if hasattr(X_numcat, 'toarray') else X_numcat
    X_text_dense = X_text.toarray() if hasattr(X_text, 'toarray') else X_text

    X_full = np.hstack([X_numcat_dense, X_text_dense])
else:
    X_full = X_numcat

print('âœ… Full feature matrix shape:', X_full.shape)

from sklearn.model_selection import train_test_split

X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    X_full, y_reg, test_size=0.2, random_state=42
)

X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(
    X_full, y_clf, test_size=0.2, random_state=42, stratify=y_clf
)

print("ðŸ“Š Regression train/test shapes:", X_train_reg.shape, X_test_reg.shape)
print("ðŸ“Š Classification train/test shapes:", X_train_clf.shape, X_test_clf.shape)

# Create Interaction Features
X_advanced = X.copy()

X_advanced['country_year_interaction'] = X_advanced['country'].astype(str) + '_' + X_advanced['start_year'].astype(str)

if 'region' in X_advanced.columns and 'shutdown_type' in X_advanced.columns:
    X_advanced['region_shutdown_interaction'] = X_advanced['region'].astype(str) + '_' + X_advanced['shutdown_type'].astype(str)

X_advanced['year_month_num'] = X_advanced['start_year'] + X_advanced['start_month'] / 100.0

if 'shutdown_extent' in X_advanced.columns and 'geo_scope' in X_advanced.columns:
     X_advanced['extent_scope_interaction'] = X_advanced['shutdown_extent'].astype(str) + '_' + X_advanced['geo_scope'].astype(str)


print("Created new interaction features.")

if text_cols:
    print("\nExploring alternative text feature engineering...")
    texts_advanced = X_advanced[text_cols].fillna('').agg(' '.join, axis=1).values

    tfidf_advanced = TfidfVectorizer(max_features=5000, ngram_range=(1,3))
    svd_advanced = TruncatedSVD(n_components=75, random_state=42)
    X_text_tfidf_advanced = tfidf_advanced.fit_transform(texts_advanced)
    X_text_advanced = svd_advanced.fit_transform(X_text_tfidf_advanced)
    print('Advanced Text features shape:', X_text_advanced.shape)
else:
    X_text_advanced = None
    print("\nNo text columns found. Skipping advanced text feature engineering.")

all_cols_advanced = X_advanced.columns.tolist()
numeric_cols_advanced = X_advanced.select_dtypes(include=['number']).columns.tolist()
object_cols_advanced = X_advanced.select_dtypes(include=['object','category']).columns.tolist()

text_cols_advanced = []
for c in object_cols_advanced:
    avg_len = X_advanced[c].fillna('').astype(str).map(len).mean()
    nunique = X_advanced[c].nunique(dropna=True)
    if (nunique > 100 and avg_len > 15) or c in text_cols:
         text_cols_advanced.append(c)

cat_cols_advanced = [c for c in object_cols_advanced if c not in text_cols_advanced]

print('\nAdvanced numeric_cols:', numeric_cols_advanced)
print('Advanced cat_cols:', cat_cols_advanced)
print('Advanced text_cols:', text_cols_advanced)

numeric_pipe_advanced = Pipeline([('impute', SimpleImputer(strategy='median')), ('scale', StandardScaler())])

low_card_advanced = [c for c in cat_cols_advanced if X_advanced[c].nunique() <= 50]
high_card_advanced = [c for c in cat_cols_advanced if c not in low_card_advanced]

cat_low_pipe_advanced = Pipeline([('impute', SimpleImputer(strategy='constant', fill_value='missing')), ('ohe', OneHotEncoder(handle_unknown='ignore'))])
cat_high_pipe_advanced = Pipeline([('impute', SimpleImputer(strategy='constant', fill_value='missing')), ('ord', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])

transformers_advanced = []
if numeric_cols_advanced:
    transformers_advanced.append(('num', numeric_pipe_advanced, numeric_cols_advanced))
if low_card_advanced:
    transformers_advanced.append(('cat_low', cat_low_pipe_advanced, low_card_advanced))
if high_card_advanced:
    transformers_advanced.append(('cat_high', cat_high_pipe_advanced, high_card_advanced))

preprocessor_advanced = ColumnTransformer(transformers_advanced, remainder='drop')
X_numcat_advanced = preprocessor_advanced.fit_transform(X_advanced)
print('Advanced Numeric+Cat transformed shape:', X_numcat_advanced.shape)

import numpy as np

if X_text_advanced is not None:

    X_numcat_advanced_dense = X_numcat_advanced.toarray() if hasattr(X_numcat_advanced, 'toarray') else X_numcat_advanced
    X_text_advanced_dense = X_text_advanced.toarray() if hasattr(X_text_advanced, 'toarray') else X_text_advanced

    X_full_advanced = np.hstack([X_numcat_advanced_dense, X_text_advanced_dense])
else:
    X_full_advanced = X_numcat_advanced

print('âœ… Advanced Full feature matrix shape:', X_full_advanced.shape)

#Normalization + Anti-Overfitting Check
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold
from sklearn.metrics import make_scorer, r2_score, accuracy_score
import numpy as np

print("\nðŸ”§ Running normalization and anti-overfitting tuning...")

#REGRESSION - Ridge with L2 regularization

best_alpha, best_r2 = None, -np.inf
cv_reg_kfold = KFold(n_splits=5, shuffle=True, random_state=42)

print("\nðŸ”¹ Tuning Ridge Regression for regularization strength...")
for alpha in [0.01, 0.1, 1.0, 5.0, 10.0]:
    reg_pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('ridge', Ridge(alpha=alpha, random_state=42))
    ])
    scores = cross_val_score(
        reg_pipe, X_train_reg, y_train_reg, cv=cv_reg_kfold, scoring=make_scorer(r2_score)
    )
    mean_score = scores.mean()
    print(f"  Î±={alpha:<5} | Mean RÂ² = {mean_score:.3f}")
    if mean_score > best_r2:
        best_r2, best_alpha = mean_score, alpha

print(f"âœ… Best Ridge Î±: {best_alpha} | Cross-val RÂ²: {best_r2:.3f}")

#CLASSIFICATION - Logistic Regression with L2 regularization
best_C, best_acc = None, -np.inf
cv_clf_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

print("\nðŸ”¹ Tuning Logistic Regression for normalization and overfitting control...")
for C in [0.01, 0.1, 0.5, 1.0, 2.0, 5.0]:
    clf_pipe = Pipeline([
        ('scaler', StandardScaler(with_mean=False)),
        ('logreg', LogisticRegression(
            C=C, penalty='l2', solver='lbfgs', max_iter=1000, random_state=42
        ))
    ])
    scores = cross_val_score(
        clf_pipe, X_train_clf, y_train_clf, cv=cv_clf_kfold, scoring='accuracy'
    )
    mean_acc = scores.mean()
    print(f"  C={C:<4} | Mean Accuracy = {mean_acc:.3f}")
    if mean_acc > best_acc:
        best_acc, best_C = mean_acc, C

print(f"âœ… Best Logistic C: {best_C} | Cross-val Accuracy: {best_acc:.3f}")

print("\nðŸ Normalization & Regularization tuning complete!")
print(f"â†’ Ridge best Î± = {best_alpha} (RÂ² = {best_r2:.3f})")
print(f"â†’ Logistic best C = {best_C} (Accuracy = {best_acc:.3f})")

# Models

import xgboost as xgb
import lightgbm as lgb
import catboost as cb

reg_models = {
    'ElasticNet': ElasticNet(random_state=42, alpha=0.1, l1_ratio=0.5),
    'RandomForest': RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1, max_depth=10, min_samples_leaf=5), # Limiting depth and samples per leaf
    'ExtraTrees': ExtraTreesRegressor(n_estimators=200, random_state=42, n_jobs=-1, max_depth=10, min_samples_leaf=5), # Limiting depth and samples per leaf
    'GradientBoosting': GradientBoostingRegressor(random_state=42, n_estimators=100, learning_rate=0.05, max_depth=3, subsample=0.8, min_samples_leaf=5), # Added regularization and complexity control
}
if xgb is not None:
    reg_models['XGBoost'] = xgb.XGBRegressor(random_state=42, n_estimators=200, n_jobs=-1, learning_rate=0.05, max_depth=5, reg_alpha=0.1, reg_lambda=0.1, colsample_bytree=0.8, subsample=0.8) # Added regularization and complexity control
if lgb is not None:
    reg_models['LightGBM'] = lgb.LGBMRegressor(random_state=42, n_estimators=200, n_jobs=-1, learning_rate=0.05, max_depth=5, reg_alpha=0.1, reg_lambda=0.1, colsample_bytree=0.8, subsample=0.8) # Added regularization and complexity control
if cb is not None:
    reg_models['CatBoost'] = cb.CatBoostRegressor(verbose=0, random_seed=42, iterations=500, learning_rate=0.05, l2_leaf_reg=3, depth=6, allow_writing_files=False) # Added regularization and complexity control


clf_models = {
    'Logistic': LogisticRegression(max_iter=2000, multi_class='multinomial', penalty='l2', C=0.5), # Adjusted regularization
    'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, max_depth=10, min_samples_leaf=5), # Limiting depth and samples per leaf
    'ExtraTrees': ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1, max_depth=10, min_samples_leaf=5), # Limiting depth and samples per leaf
    'GradientBoosting': GradientBoostingClassifier(random_state=42, n_estimators=100, learning_rate=0.05, max_depth=3, subsample=0.8, min_samples_leaf=5) # Added regularization and complexity control
}
if xgb is not None:
    clf_models['XGBoost'] = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42, n_estimators=200, n_jobs=-1, learning_rate=0.05, max_depth=5, reg_alpha=0.1, reg_lambda=0.1, colsample_bytree=0.8, subsample=0.8) # Added regularization and complexity control
if lgb is not None:
    clf_models['LightGBM'] = lgb.LGBMClassifier(random_state=42, n_estimators=200, n_jobs=-1, learning_rate=0.05, max_depth=5, reg_alpha=0.1, reg_lambda=0.1, colsample_bytree=0.8, subsample=0.8) # Added regularization and complexity control
if cb is not None:
    clf_models['CatBoost'] = cb.CatBoostClassifier(verbose=0, random_seed=42, iterations=500, learning_rate=0.05, l2_leaf_reg=3, depth=6, allow_writing_files=False) # Added regularization and complexity control

# CV setup and evaluation helpers
cv_reg = KFold(n_splits=5, shuffle=True, random_state=42)
cv_clf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

def evaluate_reg(model, X, y, cv=cv_reg):
    preds = cross_val_predict(model, X, y, cv=cv, n_jobs=-1)
    mae = mean_absolute_error(y, preds)
    rmse = math.sqrt(mean_squared_error(y, preds))
    r2 = r2_score(y, preds)
    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}

def evaluate_clf(model, X, y, cv=cv_clf):
    preds = cross_val_predict(model, X, y, cv=cv, method='predict', n_jobs=-1)
    acc = accuracy_score(y, preds)
    bal = balanced_accuracy_score(y, preds)
    f1 = f1_score(y, preds, average='macro', zero_division=0)
    return {'Accuracy': acc, 'BalancedAcc': bal, 'MacroF1': f1}

# CV setup and evaluation helpers
cv_reg = KFold(n_splits=5, shuffle=True, random_state=42)
cv_clf = KFold(n_splits=5, shuffle=True, random_state=42)


from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, mean_absolute_error, mean_squared_error, r2_score
import math
import numpy as np
import pandas as pd
import xgboost as xgb
import lightgbm as lgb
import catboost as cb


def evaluate_reg(model, X, y, cv=cv_reg):
    preds = cross_val_predict(model, X, y, cv=cv, n_jobs=-1)
    mae = mean_absolute_error(y, preds)
    rmse = math.sqrt(mean_squared_error(y, preds))
    r2 = r2_score(y, preds)
    return {'MAE': mae, 'RMSE': rmse, 'R2': r2}

def evaluate_clf(model, X, y, cv=cv_clf):
    try:
        if isinstance(model, xgb.XGBClassifier):
             return {'error': "Skipped due to cross_val_predict issues with this dataset"}

        y = y.values.ravel() if isinstance(y, pd.Series) or isinstance(y, pd.DataFrame) else y

        if isinstance(model, (lgb.LGBMClassifier, cb.CatBoostClassifier)):
             le = LabelEncoder()
             y_encoded = le.fit_transform(y)
             try:
                 preds = cross_val_predict(model, X, y_encoded, cv=cv, method='predict', n_jobs=-1)

                 preds = le.inverse_transform(preds)
             except ValueError as e:
                 if "Classification metrics can't handle a mix of multilabel-indicator and continuous targets" in str(e):
                     return {'error': f"Evaluation skipped for {type(model).__name__} due to issues with cross_val_predict 'predict' method and KFold for this dataset. Consider using StratifiedKFold if class sizes allow, or evaluate manually."}
                 else:
                     raise e
             except Exception as e:
                  return {'error': f"Evaluation failed for {type(model).__name__}: {str(e)}"}

        else:
            try:
                 preds = cross_val_predict(model, X, y, cv=cv, method='predict', n_jobs=-1)
            except Exception as e:
                 return {'error': f"Evaluation failed for {type(model).__name__}: {str(e)}"}


        acc = accuracy_score(y, preds)
        bal = balanced_accuracy_score(y, preds)
        f1 = f1_score(y, preds, average='macro', zero_division=0)

        return {'Accuracy': acc, 'BalancedAcc': bal, 'MacroF1': f1}

    except ValueError as e:
        if "The least populated class in y has only" in str(e) and isinstance(cv, StratifiedKFold):
             return {'error': f"Evaluation failed due to small class sizes for StratifiedKFold (need at least {cv.n_splits} samples per class)."}
        else:
             return {'error': str(e)}
    except Exception as e:
        return {'error': str(e)}

reg_results = []
for name, model in reg_models.items():
    print('Running evaluation for regression model:', name)
    try:
        res = evaluate_reg(model, X_full, y_reg)
        res['model'] = name
    except Exception as e:
        res = {'model': name, 'error': str(e)}
    reg_results.append(res)
    print(res)

reg_df = pd.DataFrame(reg_results)
reg_df.to_csv(OUTPUT_DIR / 'regression_results.csv', index=False)
print('Regression results saved to', OUTPUT_DIR / 'regression_results.csv')
print("\nRegression Model Performance:")
display(reg_df)

clf_results = []
for name, model in clf_models.items():
    print('Running evaluation for classification model:', name)
    try:
        res = evaluate_clf(model, X_full, y_clf)
        res['model'] = name
    except Exception as e:
        res = {'model': name, 'error': str(e)}
    clf_results.append(res)
    print(res)

clf_df = pd.DataFrame(clf_results)
clf_df.to_csv(OUTPUT_DIR / 'classification_results.csv', index=False)
print('Classification results saved to', OUTPUT_DIR / 'classification_results.csv')
print("\nClassification Model Performance:")
display(clf_df)

import pandas as pd
import os

regression_results_path = OUTPUT_DIR / 'regression_results.csv'
classification_results_path = OUTPUT_DIR / 'classification_results.csv'

if os.path.exists(regression_results_path):
    reg_df = pd.read_csv(regression_results_path)
    print("Regression Results:")
    display(reg_df)

    if 'RMSE' in reg_df.columns:
        best_reg_model_row = reg_df.loc[reg_df['RMSE'].idxmin()]
        print("\nBest Regression Model (based on lowest RMSE):")
        print(best_reg_model_row)
    else:
        print("\nRMSE column not found in regression results. Cannot determine best model based on RMSE.")

else:
    print(f"Regression results file not found at {regression_results_path}")

if os.path.exists(classification_results_path):
    clf_df = pd.read_csv(classification_results_path)
    print("\nClassification Results:")
    display(clf_df)

    if 'MacroF1' in clf_df.columns:

        clf_df_cleaned = clf_df.dropna(subset=['MacroF1'])
        if not clf_df_cleaned.empty:
            best_clf_model_row = clf_df_cleaned.loc[clf_df_cleaned['MacroF1'].idxmax()]
            print("\nBest Classification Model (based on highest MacroF1):")
            print(best_clf_model_row)
        else:
            print("\nNo classification models could be evaluated successfully.")
    else:
        print("\nMacroF1 column not found in classification results. Cannot determine best model based on MacroF1.")
else:
    print(f"Classification results file not found at {classification_results_path}")

# Save preprocessing artifacts
joblib.dump(preprocessor, OUTPUT_DIR / 'preprocessor.joblib')
if text_cols:
    joblib.dump(tfidf, OUTPUT_DIR / 'tfidf.joblib')
    joblib.dump(svd, OUTPUT_DIR / 'svd.joblib')
print('Saved preprocessors to', OUTPUT_DIR)

#USER INPUT + FUZZY MATCH + FULL FEATURE PREDICTION
from rapidfuzz import process, fuzz
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier

#SETUP
cause_col = 'actual_cause'

valid_causes = (
    X[cause_col]
    .dropna()
    .astype(str)
    .str.strip()
    .str.lower()
    .unique()
    .tolist()
)

def fuzzy_match(value, valid_values, cutoff=70):
    """Fuzzy corrects the cause string for typos."""
    if not value or not isinstance(value, str):
        return value
    value = value.strip().lower()
    best = process.extractOne(value, valid_values, scorer=fuzz.WRatio)
    if best and best[1] >= cutoff:
        return best[0]
    else:
        print(f"âš ï¸ No strong fuzzy match found for '{value}', using as-is.")
        return value

best_reg_model = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)
best_clf_model = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)

best_reg_model.fit(X_full, y_reg)
best_clf_model.fit(X_full, y_clf)

#PREDICTION FUNCTION
def predict_smart(user_cause=None, user_country=None, user_region=None, user_severity=None):
    """Predict repair duration and solution from user input + full feature defaults."""
    matched_cause = fuzzy_match(user_cause, valid_causes)
    print(f"\nðŸ§  Interpreted cause: '{matched_cause}' (from input '{user_cause}')")

    df_input = X.copy().iloc[[0]].drop(X.index[0])
    for col in X.columns:
        if X[col].dtype.kind in 'biufc':
            df_input.loc[0, col] = X[col].median()
        else:
            df_input.loc[0, col] = X[col].mode()[0]
    if cause_col in df_input.columns:
        df_input[cause_col] = matched_cause
    if user_country and 'country' in df_input.columns:
        df_input['country'] = user_country
    if user_region and 'region' in df_input.columns:
        df_input['region'] = user_region
    if user_severity and 'severity' in df_input.columns:
        df_input['severity'] = user_severity

    #TRANSFORM FEATURES
    X_input_numcat = preprocessor.transform(df_input[X.columns])
    if hasattr(X_input_numcat, "toarray"):
        X_input_numcat = X_input_numcat.toarray()
    if X_input_numcat.ndim == 1:
        X_input_numcat = X_input_numcat.reshape(1, -1)

    if text_cols:
        text_concat = df_input[text_cols].fillna('').agg(' '.join, axis=1).values
        X_input_text = svd.transform(tfidf.transform(text_concat))
        if hasattr(X_input_text, "toarray"):
            X_input_text = X_input_text.toarray()
        if X_input_text.ndim == 1:
            X_input_text = X_input_text.reshape(1, -1)

        if X_input_numcat.ndim == 1:
            X_input_numcat = X_input_numcat.reshape(1, -1)
        if X_input_text.ndim == 1:
            X_input_text = X_input_text.reshape(1, -1)

        X_input_full = np.hstack([X_input_numcat, X_input_text])
    else:
        X_input_full = X_input_numcat

    #DEBUG PRINTS
    print("\nðŸ” DEBUG INFO:")
    print("Numeric/Categorical shape:", X_input_numcat.shape)
    if text_cols:
        print("Text features shape:", X_input_text.shape)
    print("Final combined input shape:", X_input_full.shape)
    print("Data preview (first 5 columns):", X_input_full[0][:5])

    #PREDICT
    predicted_duration = best_reg_model.predict(X_input_full)[0]
    predicted_solution = best_clf_model.predict(X_input_full)[0]

    print(f"\nðŸ• Predicted repair time (duration): {predicted_duration:.2f} days")
    print(f"ðŸ§© Predicted recommended solution: {predicted_solution}")

# USER INTERACTION
print("\nEnter what you know (press Enter to skip optional fields):")
user_input_cause = input("Cause of internet shutdown (required): ").strip()
user_input_country = input("Country (optional): ").strip()
user_input_region = input("Region (optional): ").strip()
user_input_severity = input("Severity (low/medium/high - optional): ").strip()

predict_smart(
    user_cause=user_input_cause,
    user_country=user_input_country if user_input_country else None,
    user_region=user_input_region if user_input_region else None,
    user_severity=user_input_severity if user_input_severity else None
)

#Explain Predictions with SHAP
import shap
import matplotlib.pyplot as plt


if 'X_test_reg' not in locals():
    print("X_test_reg not found. Please ensure the train/test split cell has been run.")
else:

    if 'best_reg_model' not in locals():
         print("best_reg_model not found. Please ensure the model training cell has been run.")
    else:

        explainer = shap.TreeExplainer(best_reg_model)
        shap_values = explainer.shap_values(X_test_reg)

        print("\nSHAP Explanation for the first instance in the test set:")
        try:

            try:
                preprocessor_feature_names = preprocessor.get_feature_names_out()
            except:
                 preprocessor_feature_names = [f"col{i}" for i in range(X_numcat.shape[1])]

            if text_cols:
                text_feature_names = [f"text_svd_{i}" for i in range(X_text.shape[1])]
                feature_names_shap = list(preprocessor_feature_names) + text_feature_names
            else:
                 feature_names_shap = list(preprocessor_feature_names)

            if len(feature_names_shap) == shap_values.shape[1]:

                shap.summary_plot(shap_values, X_test_reg, feature_names=feature_names_shap, plot_type='bar')
            else:
                 print(f"Warning: Mismatch between number of generated feature names ({len(feature_names_shap)}) and SHAP values ({shap_values.shape[1]}). Plotting without explicit feature names.")

                 shap.summary_plot(shap_values, X_test_reg, plot_type='bar')

        except Exception as e:
             print(f"Error generating SHAP summary plot: {e}")
             print("Attempting to plot without feature names...")
             try:

                 shap.summary_plot(shap_values, X_test_reg, plot_type='bar')
             except Exception as e_fallback:
                  print(f"Fallback SHAP plot also failed: {e_fallback}")

        if len(feature_names_shap) == shap_values.shape[1]:
             shap.initjs()
             shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_reg[0,:], feature_names=feature_names_shap)
        else:
             print("\nAttempting to plot force plot without explicit feature names...")
             try:
                 shap.initjs()
                 shap.force_plot(explainer.expected_value, shap_values[0,:], X_test_reg[0,:])
             except Exception as e_fallback_force:
                 print(f"Fallback SHAP force plot also failed: {e_fallback_force}")

#model evaluation

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

sns.set(style="whitegrid", palette="viridis", font_scale=1.1)

if 'reg_df' in locals() and not reg_df.empty:
    plt.figure(figsize=(10, 5))
    sns.barplot(x='model', y='RMSE', data=reg_df)
    plt.title("Regression Model Comparison (Lower RMSE = Better)")
    plt.ylabel("RMSE")
    plt.xlabel("Model")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

    plt.figure(figsize=(10, 5))
    sns.barplot(x='model', y='R2', data=reg_df)
    plt.title("Regression Model Performance (Higher RÂ² = Better)")
    plt.ylabel("RÂ² Score")
    plt.xlabel("Model")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()
elif os.path.exists(OUTPUT_DIR / 'regression_results.csv'):
    reg_df = pd.read_csv(OUTPUT_DIR / 'regression_results.csv')
    plt.figure(figsize=(10, 5))
    sns.barplot(x='model', y='RMSE', data=reg_df)
    plt.title("Regression Model Comparison (Lower RMSE = Better)")
    plt.ylabel("RMSE")
    plt.xlabel("Model")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

    plt.figure(figsize=(10, 5))
    sns.barplot(x='model', y='R2', data=reg_df)
    plt.title("Regression Model Performance (Higher RÂ² = Better)")
    plt.ylabel("RÂ² Score")
    plt.xlabel("Model")
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()
else:
    print("Regression results not found. Please run the model evaluation cell first.")

if 'clf_df' in locals() and not clf_df.empty:
    clf_df_cleaned = clf_df.dropna(subset=['MacroF1'])
    if not clf_df_cleaned.empty:
        plt.figure(figsize=(10, 5))
        sns.barplot(x='model', y='MacroF1', data=clf_df_cleaned)
        plt.title("Classification Model Comparison (Higher Macro F1 = Better)")
        plt.ylabel("Macro F1 Score")
        plt.xlabel("Model")
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

        plt.figure(figsize=(10, 5))
        sns.barplot(x='model', y='Accuracy', data=clf_df_cleaned)
        plt.title("Classification Model Performance (Higher Accuracy = Better)")
        plt.ylabel("Accuracy")
        plt.xlabel("Model")
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

        plt.figure(figsize=(10, 5))
        sns.barplot(x='model', y='BalancedAcc', data=clf_df_cleaned)
        plt.title("Classification Model Performance (Higher Balanced Accuracy = Better)")
        plt.ylabel("Balanced Accuracy")
        plt.xlabel("Model")
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()
    else:
        print("\nNo classification models could be evaluated successfully for plotting.")

elif os.path.exists(OUTPUT_DIR / 'classification_results.csv'):
    clf_df = pd.read_csv(OUTPUT_DIR / 'classification_results.csv')

    clf_df_cleaned = clf_df.dropna(subset=['MacroF1'])
    if not clf_df_cleaned.empty:
        plt.figure(figsize=(10, 5))
        sns.barplot(x='model', y='MacroF1', data=clf_df_cleaned)
        plt.title("Classification Model Comparison (Higher Macro F1 = Better)")
        plt.ylabel("Macro F1 Score")
        plt.xlabel("Model")
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

        plt.figure(figsize=(10, 5))
        sns.barplot(x='model', y='Accuracy', data=clf_df_cleaned)
        plt.title("Classification Model Performance (Higher Accuracy = Better)")
        plt.ylabel("Accuracy")
        plt.xlabel("Model")
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

        plt.figure(figsize=(10, 5))
        sns.barplot(x='model', y='BalancedAcc', data=clf_df_cleaned)
        plt.title("Classification Model Performance (Higher Balanced Accuracy = Better)")
        plt.ylabel("Balanced Accuracy")
        plt.xlabel("Model")
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()
    else:
        print("\nNo classification models could be evaluated successfully for plotting.")
else:
    print("Classification results not found. Please run the model evaluation cell first.")

#Feature importance for the Random Forest regression model
importances = best_reg_model.feature_importances_
try:
    preprocessor_feature_names = preprocessor.get_feature_names_out()
except:

    preprocessor_feature_names = [f"col{i}" for i in range(X_numcat.shape[1])]

if X_text is not None:
    text_feature_names = [f"text_svd_{i}" for i in range(X_text.shape[1])]
    feature_names = list(preprocessor_feature_names) + text_feature_names
else:
    feature_names = list(preprocessor_feature_names)
if len(feature_names) != len(importances):
    print(f"Warning: Mismatch between number of generated feature names ({len(feature_names)}) and feature importances ({len(importances)}). Using generic feature names.")
    feature_names = [f"Feature {i}" for i in range(len(importances))]


feat_imp = pd.DataFrame({"Feature": feature_names, "Importance": importances})
feat_imp = feat_imp.sort_values("Importance", ascending=False).head(15)

plt.figure(figsize=(10,6))
sns.barplot(x="Importance", y="Feature", data=feat_imp, palette="crest")
plt.title("Top 15 Most Important Features (Repair Time Prediction)")
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.show()

# Plot actual vs predicted durations for the training data (full dataset)
import matplotlib.pyplot as plt
import seaborn as sns

y_pred = best_reg_model.predict(X_full)
plt.figure(figsize=(6,6))
sns.scatterplot(x=y_reg, y=y_pred, alpha=0.6)
plt.plot([y_reg.min(), y_reg.max()], [y_reg.min(), y_reg.max()], 'r--')
plt.xlabel("Actual Duration (Days)")
plt.ylabel("Predicted Duration (Days)")
plt.title("Actual vs Predicted Repair Time (Training Data)")
plt.show()

import plotly.express as px

fig = px.scatter(
    df,
    x='duration',
    y='region',
    color='severity',
    hover_data=['actual_cause', 'solutions'],
    title='Interactive Visualization of Repair Duration by Region and Severity'
)
fig.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

plt.figure(figsize=(10, 6))
sns.histplot(y_reg, bins=50, kde=True)
plt.title('Distribution of Repair Duration')
plt.xlabel('Duration (Days)')
plt.ylabel('Frequency')
plt.show()

print("\nDescriptive Statistics for Repair Duration:")
print(y_reg.describe())

skewness = y_reg.skew()
kurtosis = y_reg.kurtosis()
print(f"\nSkewness: {skewness:.4f}")
print(f"Kurtosis: {kurtosis:.4f}")

if abs(skewness) > 1:
    print("\nThe target variable 'duration' is significantly skewed.")
else:
    print("\nThe target variable 'duration' does not appear to be significantly skewed.")

y_reg_transformed = np.log1p(y_reg)

plt.figure(figsize=(10, 6))
sns.histplot(y_reg_transformed, bins=50, kde=True)
plt.title('Distribution of Transformed Repair Duration (log1p)')
plt.xlabel('Log(1 + Duration)')
plt.ylabel('Frequency')
plt.show()

print("\nOriginal target variable 'y_reg' and transformed variable 'y_reg_transformed' are available.")

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

plt.figure(figsize=(8, 6))
sns.boxplot(y=y_reg)
plt.title('Box Plot of Repair Duration')
plt.ylabel('Duration (Days)')
plt.show()

Q1 = y_reg.quantile(0.25)
Q3 = y_reg.quantile(0.75)
IQR = Q3 - Q1

upper_bound = Q3 + 1.5 * IQR
lower_bound = Q1 - 1.5 * IQR

outliers_count = y_reg[(y_reg > upper_bound) | (y_reg < lower_bound)].count()
print(f"\nQuantifying Outliers in 'duration' using IQR:")
print(f"Q1 (25th percentile): {Q1:.2f}")
print(f"Q3 (75th percentile): {Q3:.2f}")
print(f"IQR (Q3 - Q1): {IQR:.2f}")
print(f"Upper Bound (Q3 + 1.5*IQR): {upper_bound:.2f}")
print(f"Lower Bound (Q1 - 1.5*IQR): {lower_bound:.2f}")
print(f"\nNumber of outliers detected: {outliers_count}")
print(f"Percentage of outliers: {(outliers_count / len(y_reg) * 100):.2f}%")

from sklearn.model_selection import RandomizedSearchCV, KFold
from sklearn.metrics import mean_squared_error, make_scorer, r2_score
import numpy as np
import joblib # Ensure joblib is imported if not already

# 1. Select the best performing regression models from the baseline evaluation
# Based on the previous analysis, Gradient Boosting and CatBoost were top performers.
# We will also include LightGBM as it performed reasonably well and is efficient.

# Ensure models are available (defined in a previous cell)
# reg_models = { ... GradientBoosting, CatBoost, LightGBM ... }

selected_reg_models = {
    'GradientBoosting': reg_models['GradientBoosting'],
    'CatBoost': reg_models['CatBoost'],
    'LightGBM': reg_models['LightGBM']
}

print("Selected models for tuning:", list(selected_reg_models.keys()))

# 2. Define parameter distributions for hyperparameter tuning
# Focus on parameters controlling complexity and regularization

param_distributions = {
    'GradientBoosting': {
        'n_estimators': [100, 200, 300, 500],
        'learning_rate': [0.01, 0.05, 0.1, 0.2],
        'max_depth': [3, 4, 5, 6, 7],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4, 8],
        'subsample': [0.7, 0.8, 0.9, 1.0],
        'max_features': ['sqrt', 'log2', None] # Added max_features
    },
    'CatBoost': {
        'iterations': [200, 500, 800, 1000],
        'learning_rate': [0.01, 0.05, 0.1],
        'depth': [4, 6, 8, 10],
        'l2_leaf_reg': [1, 3, 5, 7, 9],
        'border_count': [32, 64, 128], # Added border_count
        'subsample': [0.7, 0.8, 0.9, 1.0] # Added subsample
    },
    'LightGBM': {
        'n_estimators': [100, 200, 300, 500],
        'learning_rate': [0.01, 0.05, 0.1],
        'max_depth': [-1, 3, 5, 7, 10], # -1 means no limit
        'num_leaves': [31, 63, 127], # Added num_leaves
        'min_child_samples': [20, 50, 100], # Added min_child_samples
        'subsample': [0.7, 0.8, 0.9, 1.0],
        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],
        'reg_alpha': [0, 0.1, 0.5, 1.0], # L1 regularization
        'reg_lambda': [0, 0.1, 0.5, 1.0]  # L2 regularization
    }
}

# Use negative mean squared error as the scoring metric (RandomizedSearchCV maximizes the score)
# We will evaluate RMSE and R2 manually later.
# Make a scorer for negative RMSE for tuning
neg_rmse_scorer = make_scorer(lambda y_true, y_pred: -np.sqrt(mean_squared_error(y_true, y_pred)))

# 3. Use RandomizedSearchCV for tuning
tuned_reg_models = {}
best_reg_params = {}

# Use the advanced feature set (X_full_advanced) and transformed target (y_reg_transformed)
X_train_advanced, X_test_advanced, y_train_transformed, y_test_transformed = train_test_split(
    X_full_advanced, y_reg_transformed, test_size=0.2, random_state=42
)

cv_reg_tuning = KFold(n_splits=5, shuffle=True, random_state=42) # Use KFold for regression tuning

print("\nStarting Randomized Hyperparameter Tuning...")

for name, model in selected_reg_models.items():
    print(f"\nðŸ”„ Tuning {name}...")
    # Adjust n_iter based on computational resources and parameter space size
    n_iter_search = 50 # Number of parameter settings that are sampled

    random_search = RandomizedSearchCV(
        model,
        param_distributions=param_distributions[name],
        n_iter=n_iter_search,
        scoring=neg_rmse_scorer, # Use negative RMSE for optimization
        cv=cv_reg_tuning,
        verbose=1,
        random_state=42,
        n_jobs=-1 # Use all available cores
    )

    # Fit on the training split of the advanced features and transformed target
    random_search.fit(X_train_advanced, y_train_transformed)

    best_params = random_search.best_params_
    best_score = -random_search.best_score_ # Convert negative RMSE back to positive RMSE

    print(f"âœ… Best parameters for {name}: {best_params}")
    print(f"ðŸ† Best cross-validation RMSE for {name} (transformed): {best_score:.4f}")

    tuned_reg_models[name] = random_search.best_estimator_
    best_reg_params[name] = best_params

print("\nðŸ Randomized Hyperparameter Tuning Complete!")
print("\nBest parameters found:")
for name, params in best_reg_params.items():
    print(f"- {name}: {params}")

# Save the best parameters
with open(OUTPUT_DIR / 'best_reg_params.json', 'w') as f:
    json.dump(best_reg_params, f, indent=4)
print(f"Best parameters saved to {OUTPUT_DIR / 'best_reg_params.json'}")

# The tuned models are now stored in tuned_reg_models and best_reg_params.
# The next step will evaluate these tuned models.